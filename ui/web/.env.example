# Environment variables for the Admin UI
NEXT_PUBLIC_API_URL=http://localhost:8000

# Note: LLM configuration is managed on the backend side
# The following variables are set in the backend .env file:
# - LLM_PROVIDER: The LLM provider to use (ollama, openai, etc.)
# - LLM_MODEL: The model to use for the selected provider
# - OLLAMA_BASE_URL: Base URL for Ollama service (if using Ollama)
# - OPENAI_API_KEY: API key for OpenAI (if using OpenAI)